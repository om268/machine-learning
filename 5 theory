1. Introduction to Regression

Regression is a supervised machine learning technique used for predictin!g continuous values. It analyzes the relationship between independent variables (input features) and a dependent variable (target). The main goal of regression is to find a mathematical equation that can be used to predict future outcomes based on new input data.


---

📊 2. Types of Regression

There are many types of regression models, but the two main types used in this practical are:

✅ a. Simple Linear Regression

It involves one independent variable and one dependent variable.

The relationship between the variables is represented by a straight line.

Equation:


y = mx + c

y = dependent variable (output)

x = independent variable (input)

m = slope of the line

c = intercept


✅ b. Multiple Linear Regression

It involves two or more independent variables to predict one dependent variable.

It models the relationship in a multi-dimensional space.

Equation:


y = b_0 + b_1x_1 + b_2x_2 + \cdots + b_nx_n

y = dependent variable

x₁, x₂, ..., xₙ = independent variables

b₀ = intercept

b₁, ..., bₙ = coefficients for respective variables



---

🔧 3. Steps to Implement Regression

🔹 a. Import Libraries

Use libraries like numpy, pandas, matplotlib, and scikit-learn.


🔹 b. Load Dataset

Load the data using pandas.read_csv() or create a small dataset manually.


🔹 c. Preprocess Data

Check for missing values.

Split the data into input (X) and output (y).

Normalize/scale if required.


🔹 d. Split Data

Split the dataset into training and testing sets using train_test_split().


🔹 e. Train the Model

Use LinearRegression() from sklearn.linear_model.


🔹 f. Predict Values

Use .predict() to make predictions on test data.


🔹 g. Evaluate the Model

Use metrics like:

Mean Squared Error (MSE)

R-squared Score (R²)

Mean Absolute Error (MAE)




---

📐 4. Visual Representation

For Simple Linear Regression, a scatter plot with a best-fit line can be shown.

For Multiple Regression, you may use 3D plots or heatmaps for analysis, though it may not be visually represented easily in higher dimensions.



---

🧠 5. Example Use Cases

Predicting house prices based on area, number of bedrooms, location (Multiple Regression)

Predicting student scores based on number of study hours (Simple Regression)

Forecasting sales based on advertising budget across channels (Multiple Regression)



---

📘 6. Advantages of Linear Regression

Simple to understand and implement.

Performs well on linearly correlated data.

Computationally efficient.



---

⚠️ 7. Limitations of Linear Regression

Cannot model non-linear relationships.

Sensitive to outliers.

Assumes that there is no multicollinearity (i.e., independent variables should not be highly correlated with each other).



---

🧪 8. Conclusion

Simple and Multiple Linear Regression are foundational techniques in statistics and machine learning. While Simple Linear Regression helps in understanding basic relationships between two variables, Multiple Linear Regression helps in building predictive models with multiple influencing factors.

These models are widely used in finance, healthcare, marketing, education, and many other fields.

